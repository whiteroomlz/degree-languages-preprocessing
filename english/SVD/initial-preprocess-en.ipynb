{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb54aae-bd2c-4217-9894-0f942d039998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "import glob\n",
    "import en_core_web_lg\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc34d3-d354-472b-bcdf-136015d9f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    phrase = re.sub(r\"won['’‘`]t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can['’‘`]t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"ain['’‘`]t\", \"am not\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"n['’‘`]t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"['’‘`]re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"['’‘`]s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"['’‘`]d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"['’‘`]ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"['’‘`]t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"['’‘`]ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"['’‘`]m\", \" am\", phrase)\n",
    "\n",
    "    phrase = re.sub(r'[^\\w.?!;]', ' ', phrase)\n",
    "    phrase = re.sub(' +', ' ', phrase)\n",
    "    sentences = re.split('([.;!?] *)', phrase)\n",
    "\n",
    "    return ' '.join([i.capitalize() for i in  sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a58d2-1896-4463-a15d-eff7b4c2077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_english_text(input_file, output_file):\n",
    "    nlp = en_core_web_lg.load(disable=['parser'])\n",
    "    nlp.max_length = 5000000\n",
    "    label_dict = {'NUM': 'ordinal1', 'PRON': 'pron1', 'PER': 'person1'}\n",
    "    \n",
    "    with open(input_file, 'r') as fin, open(output_file, 'w') as fout:\n",
    "        for line in fin:\n",
    "            \n",
    "            preprocessed_text = decontracted(line.strip())\n",
    "            nlp_doc = nlp(preprocessed_text)\n",
    "            \n",
    "            for token in nlp_doc:\n",
    "                if token.pos_ in label_dict:\n",
    "                    fout.write(label_dict[token.pos_])\n",
    "                    fout.write(' ')\n",
    "                    \n",
    "                elif token.lemma_.isdigit():\n",
    "                    fout.write('ordinal1')\n",
    "                    fout.write(' ')\n",
    "                    \n",
    "                elif token.pos_ != 'PUNCT':\n",
    "                    fout.write(token.lemma_.lower())\n",
    "                    fout.write(' ')\n",
    "                    \n",
    "            fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30efb2e0-1827-435a-911f-92a8447a820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_english_texts_from_folder(input_folder, output_folder):\n",
    "    files = sorted(glob.glob(input_folder + '/*'))\n",
    "    for file in tqdm.tqdm(files):\n",
    "        output_file = output_folder + '/PREPROCESSED_' + file.split('/')[-1]\n",
    "        prepare_russian_text(file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576d301-038c-4dec-9887-f73ca477041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_english_texts_from_folder('raw_english_texts', 'preprocessed_english_texts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
